{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO9VWSvaZkDVsPRXBxWGVjU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Basis for comparision of 2 models\n","* The model metrics i.e how big and \"fast\" the model is, constitute the model's metrics in this notebook.\n","  * How Big?  Space Complexity\n","    - Filesize of the \".p\" file of a frozen model\n","    - Size of state_dict_object (with or without the trained weights)\n","  * How fast? Time Complexity\n","    - MACS and FLOPs\n","    - Forward pass timing `as this only constitutes the Inference time when deployed`\n","\n"],"metadata":{"id":"GAgDIzmOlc0_"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n"],"metadata":{"id":"mI-JrrEJn7Wz","executionInfo":{"status":"ok","timestamp":1717047583355,"user_tz":-330,"elapsed":678,"user":{"displayName":"Prateek","userId":"15693021608879419017"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from torchvision.models import resnet18, resnet50, resnet101"],"metadata":{"id":"NjgJXd-mniPI","executionInfo":{"status":"ok","timestamp":1717047583356,"user_tz":-330,"elapsed":4,"user":{"displayName":"Prateek","userId":"15693021608879419017"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Device is a constant through the nb\n","DATA = torch.randn( size = (3, 3, 224, 224) )\n","\n","\n","# we create al list of models to compare\n","model_list = [ resnet18(pretrained = False).to(DEVICE),\\\n","               resnet50(pretrained = False).to(DEVICE),\n","               resnet101(pretrained = False).to(DEVICE)\n","             ]\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34mKYDdMnxk4","executionInfo":{"status":"ok","timestamp":1717047584666,"user_tz":-330,"elapsed":1314,"user":{"displayName":"Prateek","userId":"15693021608879419017"}},"outputId":"79868243-0b2a-4f91-9592-187e44023648"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"markdown","source":["# How Big the model is?\n","\n","Model size consists of 2 things:-\n","- Parameters ( model.parameters() )\n","- Buffers ( model.buffers() )\n","- Each paramter/buffer has 2 methods\n","  * p.nelement()\n","  * p.element_size()\n","\n","- Using these info can we get the size of each model?"],"metadata":{"id":"Yejyh9xRvLPa"}},{"cell_type":"code","source":["\n","# Observe:\n","# The number of learnable-params and file_size of the saved models should be equal\n","\n","def get_metrics_on_device(model: nn.Module):\n","  '''\n","    The learnable params conatins 2 things\n","      - Parameters\n","      - Buffers\n","    We can get the number of params/buffers and size of each param/buffer from the methods\n","    pertaining to each param and buffer\n","      - ele.nelements(), ele.element_size()\n","  '''\n","\n","  parameters_size = sum([ elem.element_size() * elem.nelement()  for elem in model.parameters() ])\n","  buffers_size = sum([ elem.element_size() * elem.nelement()  for elem in model.buffers() ])\n","\n","  total_size_on_device = parameters_size + buffers_size\n","  return total_size_on_device / (1024 * 1024) # to mega\n","\n","model_names = [\"resnet18\", \"resnet50\", \"resnet101\"]\n","for i, model in enumerate(model_list):\n","  size_of_model_on_device = get_metrics_on_device(model)\n","  print(f\"Size of {model_names[i]} on device is: {size_of_model_on_device:.3f} MB\")\n","print()\n","print()\n","\n","\n","\n","\n","\n","def get_size_of_network_on_disk(model: nn.Module):\n","  '''\n","    1. Get the state_dict_object\n","    2. Make a copy of it and save it to disk\n","    3. Get the filesize\n","    4. Remove the file\n","    5. Return the filesize\n","  '''\n","  import os\n","\n","  state_dict_object = model.state_dict()\n","  file_path = \"model.p\"\n","  torch.save(obj = state_dict_object, f = file_path)\n","\n","  file_size = os.path.getsize(file_path)\n","  os.remove(file_path)\n","\n","  return file_size / (1024 * 1024)\n","\n","model_names = [\"resnet18\", \"resnet50\", \"resnet101\"]\n","for i, model in enumerate(model_list):\n","  size_of_model_on_disk = get_size_of_network_on_disk(model)\n","  print(f\"Size of {model_names[i]} on disk is: {size_of_model_on_disk:.3f} MB\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPYV2tNppcEO","executionInfo":{"status":"ok","timestamp":1717047585501,"user_tz":-330,"elapsed":837,"user":{"displayName":"Prateek","userId":"15693021608879419017"}},"outputId":"025df981-556a-4568-87b3-8d34fa27f77d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of resnet18 on device is: 44.629 MB\n","Size of resnet50 on device is: 97.695 MB\n","Size of resnet101 on device is: 170.344 MB\n","\n","\n","Size of resnet18 on disk is: 44.661 MB\n","Size of resnet50 on disk is: 97.778 MB\n","Size of resnet101 on disk is: 170.507 MB\n"]}]},{"cell_type":"markdown","source":["# How Fast: Model Metrics\n","1. MAC: `1 addition + 1 multiplication`\n","2. FLOPs: `Total number of additions and multiplications`\n","3. Inference time\n","\n","**FLOPs = 2 x MAC**  "],"metadata":{"id":"xacwIRn5zPKK"}},{"cell_type":"code","source":["!wget https://optimization-thinkautonomous.s3.eu-west-3.amazonaws.com/thop_library.zip && unzip -q thop_library.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_ewc1Aku6Li","executionInfo":{"status":"ok","timestamp":1717049682590,"user_tz":-330,"elapsed":604509,"user":{"displayName":"Prateek","userId":"15693021608879419017"}},"outputId":"d4c3447a-1c3a-44d5-9f80-c3aa4d88e29c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-05-30 06:04:38--  https://optimization-thinkautonomous.s3.eu-west-3.amazonaws.com/thop_library.zip\n","Resolving optimization-thinkautonomous.s3.eu-west-3.amazonaws.com (optimization-thinkautonomous.s3.eu-west-3.amazonaws.com)... 3.5.226.246, 52.95.156.60\n","Connecting to optimization-thinkautonomous.s3.eu-west-3.amazonaws.com (optimization-thinkautonomous.s3.eu-west-3.amazonaws.com)|3.5.226.246|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 74072 (72K) [application/zip]\n","Saving to: ‘thop_library.zip.2’\n","\n","thop_library.zip.2  100%[===================>]  72.34K   358KB/s    in 0.2s    \n","\n","2024-05-30 06:04:38 (358 KB/s) - ‘thop_library.zip.2’ saved [74072/74072]\n","\n","replace __MACOSX/._thop_library? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"markdown","source":["### MACs, FLOPs and number of Parameters"],"metadata":{"id":"2KzMvZI9GloG"}},{"cell_type":"code","source":["\n","# thop_library is a cool way to calc these\n","import sys\n","sys.path.append('thop_library') # so that interpreter points to this.\n","from thop import profile\n","\n","\n","\n","def get_metrics(model: nn.Module, data: torch.Tensor):\n","  '''\n","    MACs and FLOPs\n","  '''\n","  MACs, parameters = profile( model=model, inputs = (data, ), verbose=False ) # verbose = False is imp\n","  FLOPs = 2*MACs\n","\n","  return MACs/(1e6), FLOPs/1e6, parameters/1e6\n","\n","\n","for i, model in enumerate(model_list):\n","  MMACs, MFLOPs, MParams = get_metrics(model.to(DEVICE), DATA.to(DEVICE))\n","  print( f\"MACs, FLOPs and Parameters for {model_names[i]} are: {MMACs:.3f} Mega units, {MFLOPs:.3f} Mega units, {MParams:.3f} Mega units \" )\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8xxPC9YzMKW","executionInfo":{"status":"ok","timestamp":1717049682591,"user_tz":-330,"elapsed":7,"user":{"displayName":"Prateek","userId":"15693021608879419017"}},"outputId":"f8f54b5e-15db-4402-9957-e1246b463d8b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["MACs, FLOPs and Parameters for resnet18 are: 5457.199 Mega units, 10914.398 Mega units, 11.690 Mega units \n","MACs, FLOPs and Parameters for resnet50 are: 12334.544 Mega units, 24669.088 Mega units, 25.557 Mega units \n","MACs, FLOPs and Parameters for resnet101 are: 23501.915 Mega units, 47003.830 Mega units, 44.549 Mega units \n"]}]},{"cell_type":"markdown","source":["### Inference Time"],"metadata":{"id":"49njL3gUGu3T"}},{"cell_type":"code","source":["def update_device(device):\n","  if(device != \"cpu\" and torch.cuda.is_available() ):\n","    return device\n","  return \"cpu\" # either gpu not available of explicitly cpu\n","\n","def get_average_inference_time(model: nn.Module, data: torch.Tensor, niters: int, device: str):\n","  '''\n","    1. Get the total num of datapoints across all iterations\n","    2. Set the start time\n","    3. Inference Pipeline\n","    4. Set the end time and calc the time taken\n","  '''\n","  import time\n","\n","  device = update_device(device)\n","\n","  batch_size = data.shape[0]\n","  num_datapoints = batch_size * niters\n","\n","  model = model.to(device)\n","  data = data.to(device)\n","\n","  total_time = np.inf\n","  if(niters == 0):\n","      return total_time\n","\n","  model.eval()\n","\n","  with torch.no_grad(): # Dont track the gradients and make it faster\n","    start_time = time.time()\n","    for iter in range(niters):\n","        model(data)\n","\n","    end_time = time.time()\n","\n","    total_time = end_time - start_time\n","  return ( total_time / num_datapoints ), device\n","\n","\n","for i, model in enumerate(model_list):\n","  avg_time, device = get_average_inference_time(model, DATA, 10, DEVICE)\n","  print( f\"Average Inference Time of {model_names[i]} is: {avg_time:.3f} seconds \" )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLl56GQeG0jW","executionInfo":{"status":"ok","timestamp":1717050586589,"user_tz":-330,"elapsed":1106,"user":{"displayName":"Prateek","userId":"15693021608879419017"}},"outputId":"3b9c5448-2e93-4e7a-a2b2-da7262df3b62"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Inference Time of resnet18 is: 0.001 seconds \n","Average Inference Time of resnet50 is: 0.003 seconds \n","Average Inference Time of resnet101 is: 0.005 seconds \n"]}]}]}